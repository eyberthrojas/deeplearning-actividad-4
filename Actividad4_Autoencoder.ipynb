{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Actividad 4: Deteccion de fraudes a partir de autoencoders\n",
        "\n",
        "La deteccion de fraudes es un problema de actualidad y que se ha venido trabajando con ayuda de deeplearning. En este caso realizaremos el ejercicio de entrenar un modelo de autoencoder para tratar de detectar fraudes.\n"
      ],
      "metadata": {
        "id": "5t3LWt0sUqgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/eyberthrojas/credit_cart.git"
      ],
      "metadata": {
        "id": "8YUBUyr8ZCV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TYZ1wcoiTrzT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.max_columns = 100"
      ],
      "metadata": {
        "id": "nMrn8vb-Zqs-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extrayendo los datos"
      ],
      "metadata": {
        "id": "hojfA5LuZdkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_parquet('credit_cart/creditcard.parquet')"
      ],
      "metadata": {
        "id": "lSI1cW6vZBHw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "-dFGPEaqZBKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.sample(5, random_state=0)"
      ],
      "metadata": {
        "id": "IndRH7H7ZBNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se cuenta con un dataset de 60492 registros, tenemos 29 variables de entrada, columnas V1-V28 mas columna Amount, y la etiqueta que en este caso se denomina Class"
      ],
      "metadata": {
        "id": "g2XFuffGZ6gY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distribucion de los labels:"
      ],
      "metadata": {
        "id": "2RB2UQ45ahJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Class'].value_counts()"
      ],
      "metadata": {
        "id": "Ms5aF15rZBPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La idea del modelo, es entrenar el encoder con solo datos con transacciones normales, por lo tanto el encoder entregara valores muy parecidos  a los de entrada en el caso que sean de transacciones normales, en el caso que ingrese un dato fraudulenteo, el encoder no conoce este tipo de informacion y va a entregar informacion muy diferente a la de entrada."
      ],
      "metadata": {
        "id": "S-I2YjFAazhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Primero definamos datos de train y test\n",
        "\n",
        "df_normal = data[data['Class'] == 0].copy()\n",
        "df_fraude = data[data['Class'] == 1].copy()"
      ],
      "metadata": {
        "id": "kp7KDX8jZBSF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test_normal = train_test_split(df_normal, test_size=0.2, random_state=42)\n",
        "df_train = df_train.drop(['Class'], axis=1)"
      ],
      "metadata": {
        "id": "7V7dNKLfZBUV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.concat([df_test_normal, df_fraude]).sample(frac=1, random_state=0)"
      ],
      "metadata": {
        "id": "c316nDFoZBXz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['Class'].value_counts()"
      ],
      "metadata": {
        "id": "b4xugiw4cyoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_train.to_numpy()\n",
        "y_test = df_test['Class'].to_numpy()\n",
        "X_test = df_test.drop(['Class'], axis=1).to_numpy()"
      ],
      "metadata": {
        "id": "JpwyIq4yg0k-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construccion del autoencoder\n",
        "Sabemos que tenemos 29 caracateristicas, por lo que la salida del decoder es tambien de 29 caracteristicas."
      ],
      "metadata": {
        "id": "5ywWbvQkeR87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definicion de hyperparametros"
      ],
      "metadata": {
        "id": "WLWy589IevWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Número de caracteristicas\n",
        "n_features = df_train.shape[1]\n",
        "# Numero de neuronas por capas\n",
        "neurons = [20, 8, 20, 29]\n",
        "# unciones de activación para la respectiva capa\n",
        "activations = ['tanh', 'relu', 'tanh', 'relu']\n",
        "# learning rate\n",
        "learning_rate=0.001\n",
        "# Número de épocas\n",
        "epochs=100"
      ],
      "metadata": {
        "id": "D51gInnKdVbS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer((n_features,)))\n",
        "for neuron, activation in zip(neurons, activations):\n",
        "  model.add(Dense(neuron, activation=activation))"
      ],
      "metadata": {
        "id": "tNWAnLzqe997"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de costo \n",
        "loss = tf.keras.losses.MeanSquaredError()\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss=loss)"
      ],
      "metadata": {
        "id": "sL4M_a0te-tz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "qRKLjisPpxOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=X_train, y=X_train, batch_size=32, epochs=epochs, verbose=True)"
      ],
      "metadata": {
        "id": "o19rdgX-fAbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validacion del modelo\n",
        "Como el modelo fue entrenado sólo con transacciones normales, es de esperar que al introducir un registro fraudulento la reconstrucción del dato no sea tan precisa y por tanto la diferencia entre el dato reconstruido y el original será más grande que la obtenida cuando el dato ingresado es normal"
      ],
      "metadata": {
        "id": "TLQ8vICYiiS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Así que para realizar la detección de fraudes seguiremos este procedimiento:\n",
        "\n",
        "- En primer lugar tomaremos el Autoencoder entrenado y lo usaremos para generar una predicción, usando el set de validación (X_test)\n",
        "- Luego calcularemos el error cuadrático medio entre el dato original (a la entrada del Autoencoder) y el dato reconstruido (generado a través de la predicción)\n",
        "- Posteriormente estableceremos un umbral: si el error calculado en el punto anterior supera el umbral, tendremos un registro “fraudulento”, y en caso contrario tendremos un registro “normal”."
      ],
      "metadata": {
        "id": "7Q6jXWljiybs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "aQSCYUEihJGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ecm = np.mean(np.power(X_test-X_pred,2), axis=1)"
      ],
      "metadata": {
        "id": "Od1gn1YVjkh6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "umbral_fijo = 0.99\n",
        "Y_pred = [1 if e > umbral_fijo else 0 for e in ecm]"
      ],
      "metadata": {
        "id": "bj1ugErtjwgN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, Y_pred, zero_division=0))"
      ],
      "metadata": {
        "id": "RJCVCpLpj7cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9MHlgt05kMWX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}